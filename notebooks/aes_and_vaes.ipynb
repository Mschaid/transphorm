{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "from transphorm.model_components.data_objects import SyntheticFPDataModule\n",
    "from transphorm.model_components.model_modules import VanillaAutoEncoder, Encoder, Decoder\n",
    "from pathlib import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CnnEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2D_layers =nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=12, kernel_size=2, stride = 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), \n",
    "            nn.Flatten(start_dim = -3)\n",
    "        ) \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(3000, 512), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 256), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(256, 128), \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        conv = self.conv2D_layers(x)\n",
    "        linear = self.linear_layers(conv)\n",
    "        return linear\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, 128), \n",
    "            nn.Linear(128, 512), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1000)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "    \n",
    "class AutoEncoder2D(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder, optimizer):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder()\n",
    "        self.decoder = decoder()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        \n",
    "        self.save_hyperparameters(ignore = [\"enocder\", \"decoder\"])\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.encoder(inputs)\n",
    "        x_recon = self.decoder(x)\n",
    "        return x_recon\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer(self.parameters())\n",
    "    \n",
    "    def _common_step(self, batch, batch_idx):\n",
    "        X = batch[0]\n",
    "        signal_truth = batch[0][0]\n",
    "        encoded = self.encoder(X)\n",
    "        \n",
    "        x_hat = self.decoder(encoded)\n",
    "        \n",
    "        loss = self.loss_fn(x_hat, signal_truth)\n",
    "        return loss\n",
    "        \n",
    "\n",
    "    def training_step(self,batch, batch_idx):\n",
    "        loss = self._common_step(batch, batch_idx)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch, batch_idx):\n",
    "        loss = self._common_step(batch, batch_idx) \n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/mds8301/anaconda3/envs/transphorm/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | CnnEncoder | 1.7 M \n",
      "1 | decoder | Decoder    | 612 K \n",
      "2 | loss_fn | MSELoss    | 0     \n",
      "---------------------------------------\n",
      "2.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 M     Total params\n",
      "9.257     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc33a9f79a5410ea7eea1c7966eb877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mds8301/anaconda3/envs/transphorm/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 1024 worker processes in total. Our suggested max number of worker in current system is 12 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "data_module = SyntheticFPDataModule(batch_size=10, num_workers=1000)\n",
    "data_module.prepare_data()\n",
    "data_module.setup(\"train\")\n",
    "\n",
    "auto_encoder = AutoEncoder2D(\n",
    "    encoder = CnnEncoder, \n",
    "    decoder=Decoder, \n",
    "    optimizer=torch.optim.Adam\n",
    ")\n",
    "trainer = L.Trainer(max_epochs=10)\n",
    "trainer.fit(auto_encoder, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 1000])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "load = data_module.val_dataloader()\n",
    "for i in load:\n",
    "    for j in i:\n",
    "        print(j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transphorm12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
